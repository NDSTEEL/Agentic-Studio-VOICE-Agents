'use client'

import { useState, useRef, useEffect } from 'react'
import { Mic, MicOff, Volume2, VolumeX, Settings } from 'lucide-react'

export default function VoiceAgentInterface() {
  const [isListening, setIsListening] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [response, setResponse] = useState('')
  const [isConnected, setIsConnected] = useState(false)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const audioChunksRef = useRef<Blob[]>([])

  // Simulated connection status
  useEffect(() => {
    const timer = setTimeout(() => setIsConnected(true), 1000)
    return () => clearTimeout(timer)
  }, [])

  const startListening = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      const mediaRecorder = new MediaRecorder(stream)
      mediaRecorderRef.current = mediaRecorder
      audioChunksRef.current = []

      mediaRecorder.ondataavailable = (event) => {
        audioChunksRef.current.push(event.data)
      }

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' })
        // Here you would send the audio to your API
        processAudio(audioBlob)
        stream.getTracks().forEach(track => track.stop())
      }

      mediaRecorder.start()
      setIsListening(true)
    } catch (error) {
      console.error('Error accessing microphone:', error)
    }
  }

  const stopListening = () => {
    if (mediaRecorderRef.current && isListening) {
      mediaRecorderRef.current.stop()
      setIsListening(false)
    }
  }

  const processAudio = async (audioBlob: Blob) => {
    // Simulate processing
    setTranscript('Processing your message...')
    
    // Simulate API call delay
    setTimeout(() => {
      setTranscript('Hello, I heard your voice message!')
      setResponse('This is where the AI agent response would appear. In a real implementation, this would be generated by your voice agent system.')
      setIsSpeaking(true)
      
      // Simulate speaking duration
      setTimeout(() => setIsSpeaking(false), 3000)
    }, 2000)
  }

  const toggleListening = () => {
    if (isListening) {
      stopListening()
    } else {
      startListening()
    }
  }

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-900 via-purple-900 to-slate-900">
      {/* Header */}
      <header className="p-6">
        <div className="max-w-4xl mx-auto flex items-center justify-between">
          <div className="flex items-center space-x-3">
            <div className="w-10 h-10 bg-gradient-to-r from-purple-500 to-pink-500 rounded-lg flex items-center justify-center">
              <Volume2 className="w-6 h-6 text-white" />
            </div>
            <div>
              <h1 className="text-2xl font-bold text-white">Agentic Studio</h1>
              <p className="text-purple-300">Voice Agents</p>
            </div>
          </div>
          
          <div className="flex items-center space-x-4">
            <div className={`flex items-center space-x-2 px-3 py-2 rounded-full ${
              isConnected ? 'bg-green-500/20 text-green-400' : 'bg-red-500/20 text-red-400'
            }`}>
              <div className={`w-2 h-2 rounded-full ${
                isConnected ? 'bg-green-400' : 'bg-red-400'
              }`} />
              <span className="text-sm font-medium">
                {isConnected ? 'Connected' : 'Connecting...'}
              </span>
            </div>
            
            <button className="p-2 text-gray-400 hover:text-white transition-colors">
              <Settings className="w-5 h-5" />
            </button>
          </div>
        </div>
      </header>

      {/* Main Interface */}
      <main className="flex-1 p-6">
        <div className="max-w-4xl mx-auto">
          {/* Voice Visualizer */}
          <div className="text-center mb-8">
            <div className="relative inline-flex items-center justify-center">
              {/* Pulse rings when listening */}
              {isListening && (
                <>
                  <div className="absolute w-32 h-32 rounded-full border-2 border-purple-500/30 animate-pulse-ring" />
                  <div className="absolute w-40 h-40 rounded-full border-2 border-purple-500/20 animate-pulse-ring animation-delay-75" />
                  <div className="absolute w-48 h-48 rounded-full border-2 border-purple-500/10 animate-pulse-ring animation-delay-150" />
                </>
              )}
              
              {/* Voice wave animation when speaking */}
              {isSpeaking && (
                <div className="absolute flex items-center justify-center space-x-1">
                  {[...Array(5)].map((_, i) => (
                    <div
                      key={i}
                      className="w-1 h-8 bg-gradient-to-t from-purple-500 to-pink-500 rounded-full animate-voice-wave"
                      style={{ animationDelay: `${i * 0.1}s` }}
                    />
                  ))}
                </div>
              )}
              
              {/* Main microphone button */}
              <button
                onClick={toggleListening}
                disabled={!isConnected}
                className={`relative w-24 h-24 rounded-full flex items-center justify-center transition-all duration-300 ${
                  isListening
                    ? 'bg-gradient-to-r from-red-500 to-pink-500 shadow-lg shadow-red-500/25'
                    : isConnected
                    ? 'bg-gradient-to-r from-purple-500 to-pink-500 hover:shadow-lg hover:shadow-purple-500/25'
                    : 'bg-gray-600 cursor-not-allowed'
                } ${isSpeaking ? 'scale-105' : 'hover:scale-105'}`}
              >
                {isListening ? (
                  <MicOff className="w-10 h-10 text-white" />
                ) : (
                  <Mic className="w-10 h-10 text-white" />
                )}
              </button>
            </div>
            
            <div className="mt-6">
              <p className="text-lg font-medium text-white mb-2">
                {isListening ? 'Listening...' : 
                 isSpeaking ? 'Speaking...' :
                 isConnected ? 'Tap to speak' : 'Connecting...'}
              </p>
              <p className="text-purple-300 text-sm">
                {isListening ? 'Release when finished speaking' :
                 'Hold to talk with your AI voice agent'}
              </p>
            </div>
          </div>

          {/* Conversation Display */}
          <div className="space-y-6">
            {/* User Message */}
            {transcript && (
              <div className="flex justify-end">
                <div className="bg-gradient-to-r from-purple-600 to-pink-600 rounded-2xl px-6 py-4 max-w-md">
                  <div className="flex items-center space-x-2 mb-2">
                    <div className="w-6 h-6 bg-white/20 rounded-full flex items-center justify-center">
                      <Mic className="w-3 h-3 text-white" />
                    </div>
                    <span className="text-sm font-medium text-white/90">You</span>
                  </div>
                  <p className="text-white">{transcript}</p>
                </div>
              </div>
            )}

            {/* AI Response */}
            {response && (
              <div className="flex justify-start">
                <div className="bg-slate-800 rounded-2xl px-6 py-4 max-w-md border border-slate-700">
                  <div className="flex items-center space-x-2 mb-2">
                    <div className="w-6 h-6 bg-gradient-to-r from-purple-500 to-pink-500 rounded-full flex items-center justify-center">
                      <Volume2 className="w-3 h-3 text-white" />
                    </div>
                    <span className="text-sm font-medium text-slate-300">AI Agent</span>
                    {isSpeaking && (
                      <div className="flex space-x-1 ml-2">
                        <div className="w-1 h-1 bg-purple-500 rounded-full animate-pulse" />
                        <div className="w-1 h-1 bg-purple-500 rounded-full animate-pulse animation-delay-75" />
                        <div className="w-1 h-1 bg-purple-500 rounded-full animate-pulse animation-delay-150" />
                      </div>
                    )}
                  </div>
                  <p className="text-slate-200">{response}</p>
                </div>
              </div>
            )}
          </div>

          {/* Quick Actions */}
          <div className="mt-12 flex justify-center">
            <div className="flex items-center space-x-4">
              <button 
                disabled={!isConnected}
                className="px-4 py-2 bg-slate-800 text-slate-300 rounded-lg hover:bg-slate-700 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
              >
                Clear Chat
              </button>
              <button 
                disabled={!isConnected}
                className="px-4 py-2 bg-slate-800 text-slate-300 rounded-lg hover:bg-slate-700 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
              >
                {isSpeaking ? <VolumeX className="w-4 h-4" /> : <Volume2 className="w-4 h-4" />}
              </button>
            </div>
          </div>
        </div>
      </main>
    </div>
  )
}